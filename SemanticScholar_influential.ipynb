{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7935bf22",
   "metadata": {},
   "source": [
    "## Code to get most influential references or citations\n",
    "- Documentation of API: https://api.semanticscholar.org/api-docs/#tag/Author-Data/operation/post_graph_get_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946197a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feynman/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2db2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id = \"b9b220b485d2add79118ffdc2aaa148b67fa53ef\" \n",
    "\n",
    "\n",
    "url_string = f\"https://api.semanticscholar.org/graph/v1/paper/{paper_id}/citations?fields=title,authors,isInfluential\"\n",
    "\n",
    "\n",
    "# function to load the json file that is on the url\n",
    "def load_json_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "data = load_json_from_url(url_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180ec12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total references: 234\n",
      "Influential references: 13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_paper_refs_or_cits(paper_id, fields=\"title,authors,isInfluential\", limit=100, use_references=True):\n",
    "    \"\"\"\n",
    "    Fetch all references for a paper, handling pagination.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The Semantic Scholar paper ID\n",
    "        fields: Comma-separated fields to include in the response\n",
    "        limit: Number of items to fetch per request\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (all_references, influential_references)\n",
    "    \"\"\"\n",
    "\n",
    "    suffix = \"references\" if use_references else \"citations\"\n",
    "    base_url = f\"https://api.semanticscholar.org/graph/v1/paper/{paper_id}/{suffix}\"\n",
    "    url = f\"{base_url}?fields={fields}&limit={limit}\"\n",
    "    \n",
    "    all_references = []\n",
    "    offset = 0\n",
    "    \n",
    "    while True:\n",
    "        # Add offset to URL if not first request\n",
    "        paginated_url = f\"{url}&offset={offset}\" if offset > 0 else url\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(paginated_url)\n",
    "            response.raise_for_status()  # Raise exception for HTTP errors\n",
    "            data = response.json()\n",
    "            \n",
    "            # Add fetched references to our collection\n",
    "            references = data.get('data', [])\n",
    "            all_references.extend(references)\n",
    "            \n",
    "            # Check if there are more references to fetch\n",
    "            if 'next' in data:\n",
    "                offset = data['next']\n",
    "                # Add a small delay to avoid hitting rate limits\n",
    "                time.sleep(0.5)\n",
    "            else:\n",
    "                # No more pages, we're done\n",
    "                break\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching references: {e}\")\n",
    "            break\n",
    "    \n",
    "    # Filter for influential references\n",
    "    influential_references = [ref for ref in all_references if ref.get('isInfluential', False)]\n",
    "    \n",
    "    return all_references, influential_references\n",
    "\n",
    "# Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "use_references = False\n",
    "\n",
    "paper_id = \"b9b220b485d2add79118ffdc2aaa148b67fa53ef\"\n",
    "all_refs, influential_refs = get_paper_refs_or_cits(\n",
    "    paper_id,\n",
    "    fields=\"title,authors,isInfluential,url\",\n",
    "    use_references=use_references\n",
    ")\n",
    "\n",
    "print(f\"Total references: {len(all_refs)}\")\n",
    "print(f\"Influential references: {len(influential_refs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99e34e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Influential Reference 1:\n",
      "Title: SAC-GLAM: Improving Online RL for LLM agents with Soft Actor-Critic and Hindsight Relabeling\n",
      "Authors: Loris Gaven, Cl√©ment Romac, Thomas Carta, Sylvain Lamprier, Olivier Sigaud, Pierre-Yves Oudeyer\n",
      "URL: https://www.semanticscholar.org/paper/10efca368b696136714fda841d0848f2c231516d\n",
      "\n",
      "Influential Reference 2:\n",
      "Title: Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods\n",
      "Authors: Yuji Cao, Huan Zhao, Yuheng Cheng, Ting Shu, Guolong Liu, Gaoqi Liang, Junhua Zhao, Yun Li\n",
      "URL: https://www.semanticscholar.org/paper/c44471e846846bde281779405a3b5c132fd60b00\n",
      "\n",
      "Influential Reference 3:\n",
      "Title: MLDT: Multi-Level Decomposition for Complex Long-Horizon Robotic Task Planning with Open-Source Large Language Model\n",
      "Authors: Yike Wu, Jiatao Zhang, Nan Hu, LanLing Tang, Guilin Qi, Jun Shao, Jie Ren, Wei Song\n",
      "URL: https://www.semanticscholar.org/paper/9ad90fb50754c11e60c208f1f698eed617d75d1f\n",
      "\n",
      "Influential Reference 4:\n",
      "Title: Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning\n",
      "Authors: Ruizhe Shi, Yuyao Liu, Yanjie Ze, Simon S. Du, Huazhe Xu\n",
      "URL: https://www.semanticscholar.org/paper/a2f44031dfa55f6da176955bcc37aac726de3a00\n",
      "\n",
      "Influential Reference 5:\n",
      "Title: LLaMA Rider: Spurring Large Language Models to Explore the Open World\n",
      "Authors: Yicheng Feng, Yuxuan Wang, Jiazheng Liu, Sipeng Zheng, Zongqing Lu\n",
      "URL: https://www.semanticscholar.org/paper/01a5d0ed2300ec86aa82d0e56222932f200ad692\n"
     ]
    }
   ],
   "source": [
    "use_references = False\n",
    "\n",
    "# Print first few influential references\n",
    "for i, ref in enumerate(influential_refs[:5]):\n",
    "    print(f\"\\nInfluential Reference {i+1}:\")\n",
    "    if use_references is True:\n",
    "        paper = ref.get('citedPaper', {})\n",
    "    else:\n",
    "        paper = ref.get('citingPaper', {})\n",
    "        \n",
    "    print(f\"Title: {paper.get('title')}\")\n",
    "    print(f\"Authors: {', '.join(a.get('name', '') for a in paper.get('authors', []))}\")\n",
    "    print(f\"URL: {paper.get('url')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850066da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84615359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4d8ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
