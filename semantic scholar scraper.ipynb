{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a784045-6498-458e-83da-e7b2caac9ebd",
   "metadata": {},
   "source": [
    "# For one source scrape google scholar to get a list of all citations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fcf26c",
   "metadata": {},
   "source": [
    "To run the code replace \"base_url\" and \"filename\".\n",
    "- \"base_url\" is the url of the google scholar page you want to scrape.\n",
    "\n",
    "*Note:* It should start with \"https://scholar.google.com/scholar?start=0\" . You get this url by going to page 2 and then back to page 1 by clicking on the \"previous\" button.\n",
    "- \"filename\" is the name of the json file you want to save the data to.\n",
    "\n",
    "\n",
    "Disclaimer:\n",
    "- Scholar does not like it when you scrape their website so it might block you after a while so don't run it more than needed in one day or so. If you are blocked, try a vpn or wait some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1166ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266c5d08-5a0f-42b5-83d6-8aacc6ad46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nextpage_url(url, semantic_schol = False):\n",
    "    \"\"\" Get the next page URL by adding 10 to the current page number in the URL\"\"\"\n",
    "    # Search for the number in the URL using regular expression\n",
    "    match = re.search(r'\\d+', url)\n",
    "    \n",
    "    if semantic_schol is True:\n",
    "        url_split = url.split(\"page=\")\n",
    "        if len(url_split) != 2:\n",
    "            print(\"The url does not contain exactly one time the substring: 'page='\")\n",
    "            print(\"url_split\", url_split)\n",
    "        curr_page_num = url_split[-1]\n",
    "        new_url =  url_split[0] + \"page=\" + str(int(curr_page_num) +1)\n",
    "        print(new_url)\n",
    "        return new_url\n",
    "    else:\n",
    "        if match:\n",
    "            # Extract the matched number\n",
    "            current_number = int(match.group())\n",
    "\n",
    "            # Update the number by adding 10\n",
    "            new_number = current_number + 10\n",
    "\n",
    "            # Replace the old number with the new number in the URL\n",
    "            updated_url = re.sub(r'\\d+', str(new_number), url, count=1)\n",
    "            print(updated_url)\n",
    "            return updated_url\n",
    "        else:\n",
    "            # If no number is found in the URL, return the original URL\n",
    "            print('Errooor: could not find a number in the URL')\n",
    "            return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_citation_list(citation_list, filename):\n",
    "    citation_dict = {}\n",
    "    for i, item in enumerate(citation_list):\n",
    "        citation_dict[i] = item\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(citation_dict, f)\n",
    "        \n",
    "    return citation_dict\n",
    "\n",
    "def json_to_excel(json_data, excel_file_path):\n",
    "    if \"xlsx\" not in excel_file_path:\n",
    "        excel_file_path += \".xlsx\"\n",
    "    # Convert the JSON data to a DataFrame\n",
    "    df = pd.DataFrame.from_dict(json_data, orient='index')\n",
    "\n",
    "    # Write the DataFrame to an Excel file\n",
    "    df.to_excel(excel_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6238b3-26b0-4ae9-bc5c-14acdab550f4",
   "metadata": {},
   "source": [
    "## Citation for semantic scholar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb2607e2-1370-43d8-ad31-89544c0308c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_soup_selentium(url):\n",
    "    # Set up the Selenium webdriver\n",
    "    driver = webdriver.Chrome()  # You'll need to have ChromeDriver installed and in your PATH\n",
    "\n",
    "    # Open the webpage\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to fully load (you might need to adjust the time based on the page)\n",
    "    driver.implicitly_wait(10)\n",
    "\n",
    "    # Get the page source after JavaScript has executed\n",
    "    page_source = driver.page_source\n",
    "    while \"Human Verification\" in page_source:\n",
    "        print(\"Human verification required\")\n",
    "        time.sleep(1)\n",
    "        page_source = driver.page_source\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "    # Now, you can use BeautifulSoup to parse the page source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    if \"Human Verification\" in soup.text:\n",
    "        return None\n",
    "    \n",
    "    return soup\n",
    "\n",
    "# soup = get_soup_selentium(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.semanticscholar.org/paper/Bias-in-Bios%3A-A-Case-Study-of-Semantic-Bias-in-a-De-Arteaga-Romanov/c4afa2b3eda95a1194313394901e0e96e24cefaa?sort=is-influential&page=1\"\n",
    "citation_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995a1329-9119-4fbc-8928-e6e5815c4f49",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new entry: {'title': 'Fair Text Classification with Wasserstein Independence', 'authors': \"Thibaud Leteno, Antoine Gourru, Charlotte Laclau, R'emi Emonet, Christophe Gravier\", 'tldr': \"TLDR: This paper presents a novel method for mitigating biases in neural text classification, agnostic to the model architecture, that takes inspiration from adversarial training to induce Wasserstein independence between representations learned to predict the authors' target label and the ones learning to predict some sensitive attribute.Expand\", 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/354d12991f358e12107abbe0b763ac05fa90f957?sort=is-influential#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': None, 'num_exerpts': '15 Excerpts', 'highly_influenced': 'Highly Influenced'}\n",
      "len now: 1\n",
      "new entry: {'title': 'JAB: Joint Adversarial Prompting and Belief Augmentation', 'authors': 'Ninareh Mehrabi, Palash Goyal, Rahul Gupta', 'tldr': 'TLDR: A joint framework in which an automated red teaming approach is used to probe and improve the robustness of a black-box target model via adversarial prompting and belief augmentation using iterative feedback loops is introduced.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/d42625e5d8c0ba481fc58be28849c3231250aa0b', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 2\n",
      "new entry: {'title': 'Selecting Shots for Demographic Fairness in Few-Shot Learning with Large Language Models', 'authors': 'Carlos Aguirre, Kuleen Sasse, Isabel Cachola, Mark Dredze', 'tldr': 'TLDR: This work explores the effect of shots, which directly affect the performance of models, on the fairness of LLMs as NLP classification systems and considers how different shot selection strategies affect model fairness across three standard fairness datasets.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/49319379c88eaed53c90a3e2b012a3ecb4a645c7?sort=is-influential#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '15 Excerpts', 'highly_influenced': 'Highly Influenced'}\n",
      "len now: 3\n",
      "new entry: {'title': 'Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion', 'authors': 'Kerem Zaman, Leshem Choshen, Shashank Srivastava', 'tldr': 'TLDR: The inverse is studied, investigating whether and how can model fusion interfere and reduce unwanted knowledge, and the potential of model fusion as a debiasing tool is demonstrated and its efficacy in addressing privacy concerns associated with language models is demonstrated.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/9d85ea26518bace986a2f7cdffa24edad2b20c87', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 4\n",
      "new entry: {'title': 'Model-based Counterfactual Generator for Gender Bias Mitigation', 'authors': 'E. Tokpo, T. Calders', 'tldr': 'TLDR: A combination of data processing techniques and a bi-objective training regime is proposed to develop a model-based solution for generating counterfactuals to mitigate gender bias and an empirical evaluation shows how the model alleviates the shortcomings of dictionary-based solutions.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/e0a39a21615f658736852e3de896c4d9bef11a80', 'paper_fos': 'Computer Science, Linguistics', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 5\n",
      "Found abstract: Abstract:Large Language Models (LLMs) can generate biased and toxic responses. Yet most prior work on LLM gender bias evaluation requires predefined gender-related phrases or gender stereotypes, which areâ€¦ Expand\n",
      "new entry: {'title': 'Probing Explicit and Implicit Gender Bias through LLM Conditional Text Generation', 'authors': 'Xiangjue Dong, Yibo Wang, Philip S. Yu, James Caverlee', 'tldr': 'Abstract:Large Language Models (LLMs) can generate biased and toxic responses. Yet most prior work on LLM gender bias evaluation requires predefined gender-related phrases or gender stereotypes, which areâ€¦ Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/15828a4bfe3a5b8767ab22c114cb363251ab4b02', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 6\n",
      "new entry: {'title': 'Probing LLMs for Joint Encoding of Linguistic Categories', 'authors': 'Giulio Starace, Konstantinos Papakostas, Ekaterina Shutova', 'tldr': 'TLDR: Focusing on syntax, this paper finds evidence of joint encoding both at the same (related part-of-speech (POS) classes) and different (POS classes and related syntactic dependency relations) levels of linguistic hierarchy.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/e7d493e9390ad5ebd899ffc83740ac8f078c7a61', 'paper_fos': 'Computer Science, Linguistics', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 7\n",
      "new entry: {'title': 'Do Not Harm Protected Groups in Debiasing Language Representation Models', 'authors': 'Chloe Qinyu Zhu, Rickard Stureborg, Brandon Fain', 'tldr': 'TLDR: This work examines four debiasing techniques on a real-world text classification task and shows that reducing biasing is at the cost of degrading performance for all demographic groups, including those the debiased techniques aim to protect.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/8d72ed62edc1b88f201682bae43d8eecff2a59f7', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '2 Excerpts', 'highly_influenced': None}\n",
      "len now: 8\n",
      "new entry: {'title': 'How do Language Models Bind Entities in Context?', 'authors': 'Jiahai Feng, Jacob Steinhardt', 'tldr': 'TLDR: This work analyzes LM representations and identifies the binding ID mechanism: a general mechanism for solving the binding problem, which is observed in every sufficiently large model from the Pythia and LLaMA families.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/74609184b96ee622b0ae775a3d7d86e2bfd49eb7', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 9\n",
      "new entry: {'title': 'On the Interplay between Fairness and Explainability', 'authors': 'Stephanie Brandl, Emanuele Bugliarello, Ilias Chalkidis', 'tldr': 'TLDR: It is found that bias mitigation algorithms do not always lead to fairer models and that empirical fairness and explainability are orthogonal, so forthcoming, trustworthy NLP systems should consider both.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/f6253a1c47505863be511a1fe72d0427a496b03c', 'paper_fos': 'Computer Science, Linguistics', 'paper_venue': 'arXiv.org', 'num_exerpts': '2 Excerpts', 'highly_influenced': None}\n",
      "len now: 10\n",
      "https://www.semanticscholar.org/paper/Bias-in-Bios%3A-A-Case-Study-of-Semantic-Bias-in-a-De-Arteaga-Romanov/c4afa2b3eda95a1194313394901e0e96e24cefaa?sort=is-influential&page=2\n",
      "new entry: {'title': 'Knowledge Editing for Large Language Models: A Survey', 'authors': 'Song Wang, Yaochen Zhu, Haochen Liu, Zaiyi Zheng, Chen Chen, Jundong Li', 'tldr': 'TLDR: A comprehensive and in-depth overview of recent advances in the field of Knowledge-based Model Editing (KME) is provided and an innovative taxonomy of KME techniques based on how the new knowledge is introduced into pre-trained LLMs is provided.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/42016f91e5b1da63174d45acb96bc89b64aa124d#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 11\n",
      "new entry: {'title': 'Unfairness in Machine Learning for Web Systems Applications', 'authors': 'Diego Minatel, NÃ­colas Roque dos Santos, Angelo Cesar Mendes da Silva, Mariana CÃºri, R. Marcacini, A. Lopes', 'tldr': 'TLDR: This work aims to organize in a single document known decision-making that was wholly or partially supported by machine learning models that propagated prejudices, stereotypes, and inequalities in Web Systems.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science', 'paper_venue': 'Brazilian Symposium on Multimedia and the Web', 'num_exerpts': '3 Excerpts', 'highly_influenced': None}\n",
      "len now: 12\n",
      "Found abstract: Abstract:Fairness-related assumptions about what constitutes appropriate NLG system behaviors range from invariance, where systems are expected to respond identically to social groups, to adaptation, whereâ€¦ Expand\n",
      "new entry: {'title': '\"One-size-fits-all\"? Observations and Expectations of NLG Systems Across Identity-Related Language Features', 'authors': 'Li Lucy, Su Lin Blodgett, Milad Shokouhi, Hanna M. Wallach, Alexandra Olteanu', 'tldr': 'Abstract:Fairness-related assumptions about what constitutes appropriate NLG system behaviors range from invariance, where systems are expected to respond identically to social groups, to adaptation, whereâ€¦ Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science, Linguistics', 'paper_venue': 'arXiv.org', 'num_exerpts': '3 Excerpts', 'highly_influenced': None}\n",
      "len now: 13\n",
      "new entry: {'title': 'A Novel Information-Theoretic Objective to Disentangle Representations for Fair Classification', 'authors': 'Pierre Colombo, Nathan Noiry, Guillaume Staerman, P. Piantanida', 'tldr': 'TLDR: This work adopts an information-theoretic view of the disentanglement/accuracy trade-off problem and motivates a novel family of regularizers that minimizes the mutual information between the latent representation and the sensitive attribute conditional to the target.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 14\n",
      "new entry: {'title': 'Co$^2$PT: Mitigating Bias in Pre-trained Language Models through Counterfactual Contrastive Prompt Tuning', 'authors': 'Xiangjue Dong, Ziwei Zhu, Zhuoer Wang, Maria Teleki, James Caverlee', 'tldr': 'TLDR: The experiments conducted demonstrate the effectiveness of Co$2$PT on bias mitigation during the prompt tuning process and its adaptability to existing upstream debiased language models and provide promising avenues for further enhancement in bias mitigation on downstream tasks.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/7e2a9589bcd39406e24b10485835f11ea7e9d13a#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '3 Excerpts', 'highly_influenced': None}\n",
      "len now: 15\n",
      "new entry: {'title': 'A Predictive Factor Analysis of Social Biases and Task-Performance in Pretrained Masked Language Models', 'authors': 'Yi Zhou, JosÃ© Camacho-Collados, D. Bollegala', 'tldr': 'TLDR: A comprehensive study over 39 pretrained MLMs covering different model sizes, training objectives, tokenization methods, training data domains and languages sheds light on important factors often neglected in prior literature, such as tokenization or model objectives.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science, Linguistics', 'paper_venue': 'arXiv.org', 'num_exerpts': '2 Excerpts', 'highly_influenced': None}\n",
      "len now: 16\n",
      "new entry: {'title': 'Rather a Nurse than a Physician - Contrastive Explanations under Investigation', 'authors': 'Oliver Eberle, Ilias Chalkidis, Laura Cabello, Stephanie Brandl', 'tldr': 'TLDR: It is empirically found that humans do not necessarily explain in a contrastive manner, and model-based explanations computed in both contrastive and non-contrastive settings align equally well with human rationales.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/b940088cc1fb62459ef1a848aa6658a67502b757#citing-papers', 'paper_fos': 'Computer Science, Linguistics', 'paper_venue': 'arXiv.org', 'num_exerpts': '2 Excerpts', 'highly_influenced': None}\n",
      "len now: 17\n",
      "new entry: {'title': '\"Kelly is a Warm Person, Joseph is a Role Model\": Gender Biases in LLM-Generated Reference Letters', 'authors': 'Yixin Wan, George Pu, Jiao Sun, Aparna Garimella, Kai-Wei Chang, Nanyun Peng', 'tldr': 'TLDR: The findings not only warn against using LLMs for this application without scrutinization, but also illuminate the importance of thoroughly studying hidden biases and harms in LLM-generated professional documents.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science, Linguistics', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 18\n",
      "new entry: {'title': 'Identifying and examining machine learning biases on Adult dataset', 'authors': 'Sahil Girhepuje', 'tldr': 'TLDR: The findings reveal that the stacked model aligns with individual models, confirming the resilience of model bias and underscores ethical considerations and advocates the implementation of hybrid models for a data-driven society marked by impartiality and inclusivity.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science, Economics', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 19\n",
      "new entry: {'title': 'Mitigating Simplicity Bias in Deep Learning for Improved OOD Generalization and Robustness', 'authors': 'Bhavya Vasudeva, Kameron Shahabi, Vatsal Sharan', 'tldr': 'TLDR: This work first train a simple model, and then regularize the conditional mutual information with respect to it to obtain the final model, which effectively addresses simplicity bias and leads to more features being used, enhances OOD generalization, and improves subgroup robustness and fairness.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 20\n",
      "https://www.semanticscholar.org/paper/Bias-in-Bios%3A-A-Case-Study-of-Semantic-Bias-in-a-De-Arteaga-Romanov/c4afa2b3eda95a1194313394901e0e96e24cefaa?sort=is-influential&page=3\n",
      "new entry: {'title': 'Fairness of recommender systems in the recruitment domain: an analysis from technical and legal perspectives', 'authors': 'Deepak Kumar, Tessa Grosz, Navid Rekabsaz, Elisabeth Greif, Markus Schedl', 'tldr': 'TLDR: This survey discusses the current state of fairness research considering the fairness definitions used in recruitment-related RSs (RRSs), and investigates from a technical perspective the approaches to improve fairness, like synthetic data generation, adversarial training, protected subgroup distributional constraints, and post-hoc re-ranking.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science, Law', 'paper_venue': 'Frontiers in Big Data', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 21\n",
      "new entry: {'title': 'An Investigation of Representation and Allocation Harms in Contrastive Learning', 'authors': 'Subha Maity, Mayank Agarwal, Mikhail Yurochkin, Yuekai Sun', 'tldr': 'TLDR: It is demonstrated that contrastive learning (CL), a popular variant of SSL, tends to collapse representations of minority groups with certain majority groups, and a theoretical explanation for representation harm is provided using a stochastic block model that leads to a representational neural collapse in a contrastivelearning setting.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '2 Excerpts', 'highly_influenced': None}\n",
      "len now: 22\n",
      "new entry: {'title': 'Fairness and Bias in Algorithmic Hiring', 'authors': 'Alessandro Fabris, N. Baranowska, Asia J. Biega', 'tldr': 'TLDR: This work supports a contextualized understanding and governance of this technology by highlighting current opportunities and limitations, providing recommendations for future work to ensure shared benefits for all stakeholders.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Business, Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 23\n",
      "new entry: {'title': 'Evaluating Gender Bias of Pre-trained Language Models in Natural Language Inference by Considering All Labels', 'authors': 'Panatchakorn Anantaprayoon, Masahiro Kaneko, Naoaki Okazaki', 'tldr': 'TLDR: This work proposes a meta-evaluation method for NLI bias measures, and is the first to build evaluation datasets and measure the bias of PLMs from the NLI task in Japanese and Chinese.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 24\n",
      "new entry: {'title': 'OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs', 'authors': 'Ansar Aynetdinov, A. Akbik', 'tldr': 'TLDR: OpinionGPT, a web demo in which users can ask questions and select all biases they wish to investigate, and how the bias-aware model was trained is illustrated and showcases the web application.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/a327111002d3d76510970d1eec3f03fb85314f11#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 25\n",
      "Found abstract: None\n",
      "new entry: {'title': 'Improve individual fairness in federated learning via adversarial training', 'authors': 'Jie Li, Tianqing Zhu, Wei Ren, Kim-Kwang Raymond', 'tldr': None, 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/b4ff864fd65689ad5e9099a512bded947f5ca73b#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'Computers & security', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 26\n",
      "new entry: {'title': 'Thesis Distillation: Investigating The Impact of Bias in NLP Models on Hate Speech Detection', 'authors': 'Fatma Elsafoury', 'tldr': 'TLDR: The findings of the thesis suggest that bias in NLP models impacts the task of hate speech detection from all three perspectives and that unless the social sciences are incorporated in studying bias inNLP models, the authors will not effectively overcome the current limitations of measuring and mitigating bias in nLP models.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science, Linguistics', 'paper_venue': 'arXiv.org', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 27\n",
      "new entry: {'title': 'A Survey on Fairness in Large Language Models', 'authors': 'Yingji Li, Mengnan Du, Rui Song, Xin Wang, Y. Wang', 'tldr': 'TLDR: This paper provides a comprehensive review of related research on fairness in LLMs, and introduces evaluation metrics and debiasing methods from the perspectives of intrinsic bias and extrinsic bias.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/03bf28df6e282a7e36e1686edeb9c624e6ffb13b#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '2 Excerpts', 'highly_influenced': None}\n",
      "len now: 28\n",
      "new entry: {'title': 'A multi-scenario approach to continuously learn and understand norm violations', 'authors': 'Thiago Freitas dos Santos, N. Osman, M. Schorlemmer', 'tldr': 'TLDR: Results show that the proposed framework can learn to detect norm violation in a setting with data imbalance and concept drift.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science', 'paper_venue': 'Autonomous Agents and Multi-Agent Systems', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 29\n",
      "Found abstract: Abstract:Bias amplification is a phenomenon in which models exacerbate biases or stereotypes present in the training data. In this paper, we study bias amplification in the text-to-image domain using Stableâ€¦ Expand\n",
      "new entry: {'title': 'The Bias Amplification Paradox in Text-to-Image Generation', 'authors': 'P. Seshadri, Sameer Singh, Yanai Elazar', 'tldr': 'Abstract:Bias amplification is a phenomenon in which models exacerbate biases or stereotypes present in the training data. In this paper, we study bias amplification in the text-to-image domain using Stableâ€¦ Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/c4adc81a41aa1f3dd8c835d22a8f3c34da10711d#citing-papers', 'paper_fos': 'Psychology', 'paper_venue': 'arXiv.org', 'num_exerpts': '3 Excerpts', 'highly_influenced': None}\n",
      "len now: 30\n",
      "https://www.semanticscholar.org/paper/Bias-in-Bios%3A-A-Case-Study-of-Semantic-Bias-in-a-De-Arteaga-Romanov/c4afa2b3eda95a1194313394901e0e96e24cefaa?sort=is-influential&page=4\n",
      "new entry: {'title': 'Prompt Tuning Pushes Farther, Contrastive Learning Pulls Closer: A Two-Stage Approach to Mitigate Social Biases', 'authors': 'Mengnan Du, Xin Wang, Y. Wang', 'tldr': 'TLDR: This paper proposes an adversarial training-inspired two-stagedebiasing model using Contrastive learning with Continuous Prompt Augmentation (named CCPA) to mitigate social biases in PLMsâ€™ encoding and guides the model to achieve stronger debiasing performance by adding difficulty to the training process.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/2488a75031fcd4d0f0ffe4fd0a5246325a71f241#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'Annual Meeting of the Association forâ€¦', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 31\n",
      "new entry: {'title': 'A Comprehensive Survey of Artificial Intelligence Techniques for Talent Analytics', 'authors': 'Chuan Qin, Le Zhang, Hui Xiong', 'tldr': 'TLDR: An up-to-date and comprehensive survey on AI technologies used for talent analytics in the field of human resource management and a comprehensive taxonomy of relevant research efforts based on three distinct application-driven scenarios: talent management, organization management, and labor market analysis are presented.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/2fc49aafa340f21ecd9a4740812389a8837f214f', 'paper_fos': 'Computer Science, Business', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 32\n",
      "new entry: {'title': 'Reducing the Length Divergence Bias for Textual Matching Models via Alternating Adversarial Training', 'authors': 'Lantao Zheng, Wenxin Kuang, Yupeng Hu', 'tldr': 'TLDR: This work focuses on the length divergence bias, which makes language models tend to classify samples with high length divergence as negative and vice versa, and proposes a solution to make the model pay more attention to semantics and not be affected by bias.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science', 'paper_venue': 'International Conference on Cyber Security andâ€¦', 'num_exerpts': '2 Excerpts', 'highly_influenced': None}\n",
      "len now: 33\n",
      "Found abstract: Abstract:In efforts to keep up with the rapid progress and use of large language models, gender bias research is becoming more prevalent in NLP. Non-English bias research, however, is still in its infancyâ€¦ Expand\n",
      "new entry: {'title': 'Politeness Stereotypes and Attack Vectors: Gender Stereotypes in Japanese and Korean Language Models', 'authors': 'Victor Steinborn, Antonis Maronikolakis, Hinrich SchÃ¼tze', 'tldr': 'Abstract:In efforts to keep up with the rapid progress and use of large language models, gender bias research is becoming more prevalent in NLP. Non-English bias research, however, is still in its infancyâ€¦ Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/b85ad29d40a3292863f3d2358c04b8e1c6fa43f3', 'paper_fos': 'Sociology', 'paper_venue': 'arXiv.org', 'num_exerpts': '2 Excerpts', 'highly_influenced': None}\n",
      "len now: 34\n",
      "new entry: {'title': 'Survey on Sociodemographic Bias in Natural Language Processing', 'authors': 'Vipul Gupta, Pranav Narayanan Venkit, Shomir Wilson, R. Passonneau', 'tldr': 'TLDR: This study surveys 214 papers related to sociodemographic bias in natural language processing (NLP) and concludes that current approaches on quantifying bias face reliability issues, that many of the bias metrics do not relate to real-world bias, and that debiasing techniques need to focus more on training methods.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/423f507b0293743846e29c53de548c8bbc5551e3#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 35\n",
      "new entry: {'title': 'Navigating the Audit Landscape: A Framework for Developing Transparent and Auditable XR', 'authors': 'Chris Norval, Richard Cloete, Jatinder Singh', 'tldr': 'TLDR: A framework focuses on supporting the building and instrumentation of an XR system for transparency aims, elaborating key considerations regarding the capture and management of audit data during system operation.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science', 'paper_venue': 'Conference on Fairness, Accountability andâ€¦', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 36\n",
      "new entry: {'title': 'Are fairness metric scores enough to assess discrimination biases in machine learning?', 'authors': 'Fanny Jourdan, L. Risser, J. Loubes, Nicholas M. Asher', 'tldr': 'TLDR: Novel experiments shedding light on the shortcomings of current metrics for assessing biases of gender discrimination made by machine learning algorithms on textual data are presented, and how reliable are different popular measures of bias when the size of the training set is simply sufficient to learn reasonably accurate predictions is questioned.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/4a4a94dcff78b188a23e7340567cbb6f155e73f3?sort=is-influential#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'TRUSTNLP', 'num_exerpts': '6 Excerpts', 'highly_influenced': 'Highly Influenced'}\n",
      "len now: 37\n",
      "new entry: {'title': 'LEACE: Perfect linear concept erasure in closed form', 'authors': 'Nora Belrose, David Schneider-Joseph, Shauli Ravfogel, Ryan Cotterell, Edward Raff, Stella Rose Biderman', 'tldr': 'TLDR: LEAst-squares Concept Erasure (LEACE) is introduced, a closed-form method which provably prevents all linear classifiers from detecting a concept while changing the representation as little as possible, as measured by a broad class of norms.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/22ae20f20d0b4e6451ae41cc76e58a9221e90df9#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '2 Excerpts', 'highly_influenced': None}\n",
      "len now: 38\n",
      "new entry: {'title': 'Benchmarking Robustness of Adaptation Methods on Pre-trained Vision-Language Models', 'authors': 'Shuo Chen, Jindong Gu, Zhen Han, Yunpu Ma, Philip H. S. Torr, Volker Tresp', 'tldr': 'TLDR: The robustness of 11 widely-used adaptation methods across 4 vision-language datasets under multimodal corruptions is assessed and it is indicated that increasing the number of adaptation data and parameters does not guarantee enhanced robustness; instead it results in even lower robustness.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/8213492345c67d2b0e692b6bb5c814d4f1aef8d2#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 39\n",
      "new entry: {'title': 'The Hidden Language of Diffusion Models', 'authors': 'Hila Chefer, Oran Lang, Lior Wolf', 'tldr': 'TLDR: Conceptor is presented, a novel method to interpret the internal representation of a textual concept by a diffusion model by decomposing the concept into a small set of human-interpretable textual elements, which reveals non-trivial structures in the representations of concepts.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/9ecda80a94213c4d8322ccfb34ff6e1bfc4a9390#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '2 Excerpts', 'highly_influenced': None}\n",
      "len now: 40\n",
      "https://www.semanticscholar.org/paper/Bias-in-Bios%3A-A-Case-Study-of-Semantic-Bias-in-a-De-Arteaga-Romanov/c4afa2b3eda95a1194313394901e0e96e24cefaa?sort=is-influential&page=5\n",
      "new entry: {'title': 'Trade-Offs Between Fairness and Privacy in Language Modeling', 'authors': 'Cleo Matzken, Steffen Eger, Ivan Habernal', 'tldr': 'TLDR: The extent to which privacy preservation comes at the price of worsening biases in classification tasks is explored when both privacy preservation and de-biasing techniques are incorporated into training text generation models.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science', 'paper_venue': 'Annual Meeting of the Association forâ€¦', 'num_exerpts': '2 Excerpts', 'highly_influenced': None}\n",
      "len now: 41\n",
      "new entry: {'title': 'On Bias and Fairness in NLP: How to have a fairer text classification?', 'authors': 'Fatma Elsafoury, Stamos Katsigiannis, N. Ramzan', 'tldr': 'TLDR: It is found that overamplification bias is the most impactful bias on the fairness of text classification and that removing overamPLification bias by fine-tuning the LM models on a dataset with balanced representations of the different identity groups leads to fairer text classification models.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/9f14f4a5f0ed3452f17094a36cabe99180ab76a9#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 42\n",
      "new entry: {'title': 'Should We Attend More or Less? Modulating Attention for Fairness', 'authors': 'A. Zayed, GonÃ§alo Mordido, S. Shabanian, Sarath Chandar', 'tldr': 'TLDR: This work investigates the role of attention, a widely-used technique in current state-of-the-art NLP models, in the propagation of social biases and proposes a novel method for modulating attention weights to improve model fairness after training.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/6927a5b0152433a199ab4974ad85e787454d6a30#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '3 Excerpts', 'highly_influenced': None}\n",
      "len now: 43\n",
      "new entry: {'title': 'In the Name of Fairness: Assessing the Bias in Clinical Record De-identification', 'authors': 'Yuxin Xiao, S. Lim, T. Pollard, M. Ghassemi', 'tldr': 'TLDR: This work investigates the bias of de-identification systems on names in clinical notes via a large-scale empirical analysis and proposes a simple and method-agnostic solution by fine-tuning de-Identification methods with clinical context and diverse names.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/b9badb4332ded00103d61663058db2bcfeeae15c#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'Conference on Fairness, Accountability andâ€¦', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 44\n",
      "new entry: {'title': 'Shielded Representations: Protecting Sensitive Attributes Through Iterative Gradient-Based Projection', 'authors': 'Shadi Iskander, Kira Radinsky, Yonatan Belinkov', 'tldr': 'TLDR: This work proposes Iterative Gradient-Based Projection (IGBP), a novel method for removing non-linear encoded concepts from neural representations that is effective in mitigating bias through intrinsic and extrinsic evaluations, with minimal impact on downstream task accuracy.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/54450cceb117d7f43d160085dac8d0a1858d78d5#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'Annual Meeting of the Association forâ€¦', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 45\n",
      "new entry: {'title': 'Surfacing Biases in Large Language Models using Contrastive Input Decoding', 'authors': 'G. Yona, Or Honovich, Itay Laish, Roee Aharoni', 'tldr': 'TLDR: Contrastive Input Decoding (CID) is proposed: a decoding algorithm to generate text given two inputs, where the generated text is likely given one input but unlikely given the other.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/b20e93425a70f4ca3cf68abe921e8c3812e0c471#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 46\n",
      "new entry: {'title': 'Stroke Home Rehabilitation Approach Using Mobile Application Based on PostNet Machine Learning Model', 'authors': 'Utpal Chandra Das, N. Le, W. Benjapolakul, Timporn Vitoonpong, C. Pluempitiwiriyawej', 'tldr': 'TLDR: This study proposes a Convolutional Neural Network based pose net machine learning (ML) model for stroke home rehabilitation using pose detection and classification with a skeleton base model and human pose estimation drawing.Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science, Medicine', 'paper_venue': 'International Conference on Medical and Healthâ€¦', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 47\n",
      "new entry: {'title': 'COCKATIEL: COntinuous Concept ranKed ATtribution with Interpretable ELements for explaining neural net classifiers on NLP tasks', 'authors': 'Fanny Jourdan, Agustin Picard, Thomas Fel, L. Risser, J. Loubes, Nicholas M. Asher', 'tldr': 'TLDR: COCKATIEL is a novel, post-hoc, concept-based, model-agnostic XAI technique that generates meaningful explanations from the last layer of a neural net model trained on an NLP classification task by using Non-Negative Matrix Factorization to discover the concepts the model leverages to make predictions and by exploiting a Sensitivity Analysis to estimate accurately the importance of each of these concepts for the model.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/a0c3da053af5d47b1eda747e120fd95267c28f75#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'Annual Meeting of the Association forâ€¦', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 48\n",
      "new entry: {'title': 'MLHOps: Machine Learning for Healthcare Operations', 'authors': 'Faiza Khan Khattak, Vallijah Subasri, Frank Rudzicz', 'tldr': 'TLDR: This work provides guidance across the full pipeline of MLHOps from conception to initial and ongoing deployment and ethical considerations (including bias, fairness, interpretability, and privacy).Expand', 'year': '2023', 'paper_link': None, 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '2 Excerpts', 'highly_influenced': None}\n",
      "len now: 49\n",
      "Found abstract: None\n",
      "new entry: {'title': 'Measuring and mitigating language model biases in abusive language detection', 'authors': 'Rui Song, Fausto Giunchiglia, Yingji Li, Lida Shi, Hao Xu', 'tldr': None, 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/ea5506172739270ff59384b759ba2a2689566ed6#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'Information Processing & Management', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 50\n",
      "https://www.semanticscholar.org/paper/Bias-in-Bios%3A-A-Case-Study-of-Semantic-Bias-in-a-De-Arteaga-Romanov/c4afa2b3eda95a1194313394901e0e96e24cefaa?sort=is-influential&page=6\n",
      "new entry: {'title': 'Path-specific Causal Fair Prediction via Auxiliary Graph Structure Learning', 'authors': 'Liuyi Yao, Yaliang Li, Jing Gao', 'tldr': 'TLDR: This work provides theoretical analysis on the generalization bound for the proposed fair prediction method, and conducts a series of experiments to demonstrate that the proposed framework can provide better prediction performance and algorithm fairness trade-off.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/16f9421df9fe95ecbe5f6c94f7b9b23d32479b75#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'The Web Conference', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 51\n",
      "new entry: {'title': 'Show me a \"Male Nurse\"! How Gender Bias is Reflected in the Query Formulation of Search Engine Users', 'authors': 'Simone Kopeinik, Martina Mara, Linda Ratz, Klara Krieg, M. Schedl, Navid Rekabsaz', 'tldr': 'TLDR: This work investigates the replication of stereotypical gender representations by users in formulating online search queries and defines the disproportionate mention of the gender that does not conform to the prototypical representative of a searched domain as an indication of bias.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/605755564694f22a63ad5f17116704077182cdbd#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'International Conference on Human Factors inâ€¦', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 52\n",
      "new entry: {'title': 'Inspecting and Editing Knowledge Representations in Language Models', 'authors': 'Evan Hernandez, Belinda Z. Li, Jacob Andreas', 'tldr': \"TLDR: REMEDI is described, a method for learning to map statements in natural language to fact encodings in an LM's internal representation system, and offers steps toward general tools for fine-grained inspection and control of knowledge in LMs.Expand\", 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/a206a0c96d6076c6ab081288b0c2c95d3c7efd64#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': None, 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 53\n",
      "new entry: {'title': 'Whose Opinions Do Language Models Reflect?', 'authors': 'Shibani Santurkar, Esin Durmus, Faisal Ladhak, Cinoo Lee, Percy Liang, Tatsunori Hashimoto', 'tldr': 'TLDR: This work creates OpinionsQA, a new dataset for evaluating the alignment of LM opinions with those of 60 US demographic groups over topics ranging from abortion to automation, and finds substantial misalignment.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/e38a29f6463f38f43797b128673b9e44d18a991e#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'International Conference on Machine Learning', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 54\n",
      "new entry: {'title': 'Stable Bias: Analyzing Societal Representations in Diffusion Models', 'authors': 'A. Luccioni, Christopher Akiki, Margaret Mitchell, Yacine Jernite', 'tldr': 'TLDR: This work proposes a new method for exploring the social biases in TTI systems that relies on characterizing the variation in generated images triggered by enumerating gender and ethnicity markers in the prompts, and comparing it to the variation engendered by spanning different professions.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/9116c50561007cd69cc24a60c7593a5425f57fcc#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 55\n",
      "new entry: {'title': 'Fairness Evaluation in Text Classification: Machine Learning Practitioner Perspectives of Individual and Group Fairness', 'authors': 'Zahra Ashktorab, Benjamin Hoover, Mikhail Yurochkin', 'tldr': 'TLDR: Fairness assessment strategies involving personal experiences or how users form groups of identity tokens to test model fairness are discovered and recommendations for interactive tools for evaluating fairness in text classification are provided.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/f0ba8839432118920890be24f93213ddf2e06118#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'International Conference on Human Factors inâ€¦', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 56\n",
      "new entry: {'title': 'How optimal transport can tackle gender biases in multi-class neural-network classifiers for job recommendations?', 'authors': 'Fanny Jourdan, Titon Tshiongo Kaninku, Nicholas M. Asher, Jean-Michel Loubes, L. Risser', 'tldr': 'TLDR: This work presents a novel optimal transport strategy to mitigate undesirable algorithmic biases in multi-class neural network classification and uses it on the Bios dataset, for which the learning task consists of predicting the occupation of female and male individuals, based on their LinkedIn biography.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/b23dfb9c94fe93a3fa1524ec9a1e21f3c2db1b1c#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'Algorithms', 'num_exerpts': '11 Excerpts', 'highly_influenced': 'Highly Influenced'}\n",
      "len now: 57\n",
      "new entry: {'title': 'In-Depth Look at Word Filling Societal Bias Measures', 'authors': \"MatÃºÅ¡ Pikuliak, Ivana BenovÃ¡, Viktor Bachrat'y\", 'tldr': 'TLDR: This work analyzes the validity of two measures of societal bias in language models â€“ StereoSet and CrowS-Pairs and shows that these measures produce unexpected and illogical results when appropriate control group samples are constructed.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/78665358e27c6c09fbb99b7642b70834666993b9#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'Conference of the European Chapter of theâ€¦', 'num_exerpts': '1 Excerpt', 'highly_influenced': None}\n",
      "len now: 58\n",
      "new entry: {'title': 'A Review of the Role of Causality in Developing Trustworthy AI Systems', 'authors': 'Niloy Ganguly, Dren Fazlija, W. Nejdl', 'tldr': 'TLDR: This review aims to provide the reader with an overview of causal methods that have been developed to improve the trustworthiness of AI models and hope that this contribution will motivate future research on causality-based solutions for trustworthy AI.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/faf261c4dc30f71ab3c147e5fee070f780572cd6#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'arXiv.org', 'num_exerpts': None, 'highly_influenced': None}\n",
      "len now: 59\n",
      "new entry: {'title': 'Parameter-efficient Modularised Bias Mitigation via AdapterFusion', 'authors': 'Deepak Kumar, Oleg Lesota, Navid Rekabsaz', 'tldr': 'TLDR: DAM (Debiasing with Adapter Modules) is introduced â€“ a debiasing approach to first encapsulate arbitrary bias mitigation functionalities into separate adapters, and then add them to the model on-demand in order to deliver fairness qualities.Expand', 'year': '2023', 'paper_link': 'https://www.semanticscholar.org/reader/fe7a0612b24b48fe09304af39cdb27d8e33697c6#citing-papers', 'paper_fos': 'Computer Science', 'paper_venue': 'Conference of the European Chapter of theâ€¦', 'num_exerpts': '5 Excerpts', 'highly_influenced': 'Highly Influenced'}\n",
      "len now: 60\n",
      "https://www.semanticscholar.org/paper/Bias-in-Bios%3A-A-Case-Study-of-Semantic-Bias-in-a-De-Arteaga-Romanov/c4afa2b3eda95a1194313394901e0e96e24cefaa?sort=is-influential&page=7\n",
      "Human verification required\n",
      "Human verification required\n",
      "Human verification required\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=113.0.5672.126)\nStacktrace:\n#0 0x560864849133 <unknown>\n#1 0x56086457d966 <unknown>\n#2 0x560864557cec <unknown>\n#3 0x5608645dec0f <unknown>\n#4 0x5608645f1c2b <unknown>\n#5 0x5608645d99a3 <unknown>\n#6 0x5608645ae46a <unknown>\n#7 0x5608645af55e <unknown>\n#8 0x560864808cae <unknown>\n#9 0x56086480c8fe <unknown>\n#10 0x560864815f20 <unknown>\n#11 0x56086480d923 <unknown>\n#12 0x5608647e0c0e <unknown>\n#13 0x560864830b08 <unknown>\n#14 0x560864830c97 <unknown>\n#15 0x560864841113 <unknown>\n#16 0x7f9b68766609 start_thread\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/home/leonardo/Documents/scholar_scraper/semantic scholar scraper.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/leonardo/Documents/scholar_scraper/semantic%20scholar%20scraper.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m\"\"\" Note: sometimes it crashes therefore the base_url is updated, so you can just rerun this cell and it will continue where it left off\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/leonardo/Documents/scholar_scraper/semantic%20scholar%20scraper.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/leonardo/Documents/scholar_scraper/semantic%20scholar%20scraper.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     soup \u001b[39m=\u001b[39m get_soup_selentium(base_url)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/leonardo/Documents/scholar_scraper/semantic%20scholar%20scraper.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mif\u001b[39;00m soup:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/leonardo/Documents/scholar_scraper/semantic%20scholar%20scraper.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         citation_page \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpaper-detail-content-card result-page\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/leonardo/Documents/scholar_scraper/semantic scholar scraper.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leonardo/Documents/scholar_scraper/semantic%20scholar%20scraper.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mHuman verification required\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leonardo/Documents/scholar_scraper/semantic%20scholar%20scraper.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/leonardo/Documents/scholar_scraper/semantic%20scholar%20scraper.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     page_source \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mpage_source\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leonardo/Documents/scholar_scraper/semantic%20scholar%20scraper.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Close the browser\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/leonardo/Documents/scholar_scraper/semantic%20scholar%20scraper.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m driver\u001b[39m.\u001b[39mquit()\n",
      "File \u001b[0;32m~/anaconda3/envs/rl_genderbias/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:448\u001b[0m, in \u001b[0;36mWebDriver.page_source\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpage_source\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    441\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Gets the source of the current page.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \n\u001b[1;32m    443\u001b[0m \u001b[39m    :Usage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[39m            driver.page_source\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute(Command\u001b[39m.\u001b[39mGET_PAGE_SOURCE)[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/rl_genderbias/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    346\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> 347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n\u001b[1;32m    348\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    349\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/rl_genderbias/lib/python3.11/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=113.0.5672.126)\nStacktrace:\n#0 0x560864849133 <unknown>\n#1 0x56086457d966 <unknown>\n#2 0x560864557cec <unknown>\n#3 0x5608645dec0f <unknown>\n#4 0x5608645f1c2b <unknown>\n#5 0x5608645d99a3 <unknown>\n#6 0x5608645ae46a <unknown>\n#7 0x5608645af55e <unknown>\n#8 0x560864808cae <unknown>\n#9 0x56086480c8fe <unknown>\n#10 0x560864815f20 <unknown>\n#11 0x56086480d923 <unknown>\n#12 0x5608647e0c0e <unknown>\n#13 0x560864830b08 <unknown>\n#14 0x560864830c97 <unknown>\n#15 0x560864841113 <unknown>\n#16 0x7f9b68766609 start_thread\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Note: sometimes it crashes therefore the base_url is updated, so you can just rerun this cell and it will continue where it left off\"\"\"\n",
    "while True:\n",
    "    soup = get_soup_selentium(base_url)\n",
    "    if soup:\n",
    "\n",
    "        citation_page = soup.find('div', class_='paper-detail-content-card result-page')\n",
    "        for citation in citation_page.find_all('div', class_='cl-paper-row citation-list__paper-row'):\n",
    "            title = citation.find('h3', class_='cl-paper-title').text.strip()\n",
    "\n",
    "            # Get authors\n",
    "            authors_tag = citation.find('ul', class_='cl-paper__bulleted-row')\n",
    "            authors = citation.find('span', class_='cl-paper-authors')\n",
    "            if authors is not None:\n",
    "                authors = authors.find_all('a')\n",
    "                author_list = [author.text for author in authors]\n",
    "                author_string = \", \".join(author_list)\n",
    "                authors = author_string\n",
    "\n",
    "            # Get metdata, year and link to paper PDF\n",
    "            paper_fos = citation.find(\"span\", class_= \"cl-paper-fos\")\n",
    "            paper_fos = paper_fos.text if paper_fos is not None else paper_fos\n",
    "            paper_venue = citation.find('span', class_='cl-paper-venue')\n",
    "            paper_venue = paper_venue.text if paper_venue is not None else paper_venue\n",
    "            \n",
    "            year = citation.find(\"span\", class_= \"cl-paper-pubdates\").text\n",
    "\n",
    "            # Get the link to the paper on semantic scholar\n",
    "            link_paper = citation.find('li', class_='cl-paper-stats__item')\n",
    "            if link_paper is not None:\n",
    "                link_paper = link_paper.find(\"a\")['href'] if link_paper is not None else None\n",
    "                link2 = \"https://www.semanticscholar.org\" + link_paper\n",
    "                link_paper = link2.replace(\"/paper\", \"/reader\")\n",
    "                \n",
    "            # Get the number of times this paper cites the orignial paper\n",
    "            num_exerpts = citation.find(\"button\", {\"data-heap-type\":\"excerpt\"})\n",
    "            num_exerpts = num_exerpts.text if num_exerpts is not None else num_exerpts\n",
    "            \n",
    "            # Get boolean if the paper is highly influenced by the original paper\n",
    "            highly_influenced = citation.find(\"span\", class_=\"cl-paper-stats__hideable-text\")\n",
    "            highly_influenced = highly_influenced.text if highly_influenced is not None else highly_influenced\n",
    "\n",
    "            # Get either the TLDR or the abstract -whichever is available\n",
    "            tldr = citation.find(\"div\", class_=\"tldr-abstract-replacement text-truncator\")\n",
    "            tldr = tldr.text.replace(\"TLDR\", \"TLDR: \") if tldr is not None else tldr\n",
    "            if tldr is None:\n",
    "                tldr = citation.find(\"div\", class_=\"cl-paper-abstract\")\n",
    "                tldr = \"Abstract:\" + tldr.text if tldr is not None else tldr\n",
    "                print(\"Found abstract:\", tldr)\n",
    "\n",
    "\n",
    "            citation_list.append({\n",
    "                'title': title,\n",
    "                'authors': authors,\n",
    "                'tldr': tldr,\n",
    "                'year': year,\n",
    "                'paper_link':link_paper,\n",
    "                'paper_fos':paper_fos,\n",
    "                'paper_venue':paper_venue,\n",
    "                'num_exerpts':num_exerpts,\n",
    "                'highly_influenced':highly_influenced\n",
    "            })\n",
    "            print(\"new entry:\", citation_list[-1])\n",
    "            print(\"len now:\", len(citation_list))\n",
    "        next_page_url = get_nextpage_url(base_url, semantic_schol=True)\n",
    "        base_url = next_page_url\n",
    " \n",
    "    else:\n",
    "        print(f\"Error: could not load page\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.semanticscholar.org/paper/Bias-in-Bios%3A-A-Case-Study-of-Semantic-Bias-in-a-De-Arteaga-Romanov/c4afa2b3eda95a1194313394901e0e96e24cefaa?sort=is-influential&page=7\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(base_url)\n",
    "print(len(citation_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_list2 = citation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"biasbios_semantic5_temp\"\n",
    "citation_json = store_citation_list(citation_list, filename + \".json\")\n",
    "json_to_excel(citation_json, filename + \".xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_genderbias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
